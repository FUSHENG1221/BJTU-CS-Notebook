import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import json
import os
from datetime import datetime
from rouge_score import rouge_scorer

from model import Transformer
from config import config
from data_loader import get_data_loaders
from utils import set_seed

import warnings
warnings.filterwarnings("ignore")# å¿½ç•¥è­¦å‘Šè¾“å‡º
plt.rcParams["font.sans-serif"] = ["SimHei"]# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ˜¾ç¤ºï¼ˆè§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜ï¼‰
plt.rcParams["axes.unicode_minus"] = False# æ˜¾ç¤ºè´Ÿå·

class AblationTransformer(Transformer):
    """
    æ¶ˆèå®éªŒä¸“ç”¨Transformeræ¨¡å‹
    æ”¯æŒå¯ç”¨/ç¦ç”¨ä½ç½®ç¼–ç åŠŸèƒ½
    """
    def __init__(self, config, tokenizer=None, use_positional_encoding=True):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒæ¨¡å‹
        Args:
            config: æ¨¡å‹é…ç½®
            tokenizer: åˆ†è¯å™¨
            use_positional_encoding: æ˜¯å¦ä½¿ç”¨ä½ç½®ç¼–ç ï¼ˆæ¶ˆèå˜é‡ï¼‰
        """
        super().__init__(config, tokenizer)
        self.use_positional_encoding = use_positional_encoding

        # å¦‚æœç¦ç”¨ä½ç½®ç¼–ç ï¼Œå°†ä½ç½®ç¼–ç å±‚æ›¿æ¢ä¸ºæ’ç­‰æ˜ å°„
        if not use_positional_encoding:
            self.pos_encoding = nn.Identity()  # æ’ç­‰æ˜ å°„ï¼Œä¸æ·»åŠ ä½ç½®ä¿¡æ¯

    def encode(self, src, src_mask=None):
        """é‡å†™ç¼–ç æ–¹æ³•ï¼Œæ”¯æŒä½ç½®ç¼–ç å¼€å…³"""
        if src_mask is None:
            src_mask = self._create_src_mask(src)

        # è¯åµŒå…¥
        x = self.embedding(src)

        # æ¡ä»¶ä½ç½®ç¼–ç ï¼Œæ ¹æ®`æ˜¯å¦ä½¿ç”¨ä½ç½®ç¼–ç ï¼ˆæ¶ˆèå˜é‡ï¼‰`å†³å®š
        if self.use_positional_encoding:
            x = self.pos_encoding(x)

        x = self.dropout(x)

        encoder_self_attentions = []
        for layer in self.encoder_layers:
            x, self_attn = layer(x, src_mask)
            encoder_self_attentions.append(self_attn)

        return x, encoder_self_attentions

    def decode(self, tgt, encoder_output, src_mask=None, tgt_mask=None):
        """é‡å†™è§£ç æ–¹æ³•ï¼Œæ”¯æŒä½ç½®ç¼–ç å¼€å…³"""
        if tgt_mask is None:
            tgt_mask = self._create_tgt_mask(tgt.size(1))

        # è¯åµŒå…¥
        x = self.embedding(tgt)

        # æ¡ä»¶ä½ç½®ç¼–ç 
        if self.use_positional_encoding:
            x = self.pos_encoding(x)

        x = self.dropout(x)

        decoder_self_attentions = []
        decoder_cross_attentions = []
        for layer in self.decoder_layers:
            x, self_attn, cross_attn = layer(x, encoder_output, src_mask, tgt_mask)
            decoder_self_attentions.append(self_attn)
            decoder_cross_attentions.append(cross_attn)

        logits = self.output_projection(x)
        return logits, decoder_self_attentions, decoder_cross_attentions


class AblationStudy:
    """
    ä½ç½®ç¼–ç æ¶ˆèå®éªŒç±»
    æ¯”è¾ƒä½¿ç”¨ä½ç½®ç¼–ç  vs ä¸ä½¿ç”¨ä½ç½®ç¼–ç çš„æ¨¡å‹æ€§èƒ½å·®å¼‚
    """

    def __init__(self, config, tokenizer,train_loader, val_loader, test_loader):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒ

        Args:
            config: å®éªŒé…ç½®
            tokenizer: åˆ†è¯å™¨å®ä¾‹
        """
        self.config = config
        self.tokenizer = tokenizer
        self.train_loader, self.val_loader, self.test_loader = train_loader, val_loader, test_loader
        self.device = config.device

        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir = "../results/ablation_study"
        os.makedirs(self.results_dir, exist_ok=True)

        # å®éªŒè®°å½•
        self.results = {
            "experiment_info": {
                "timestamp": datetime.now().isoformat(),
                "config": config.__dict__,
                "description": "ä½ç½®ç¼–ç æ¶ˆèå®éªŒï¼šæ¯”è¾ƒä½¿ç”¨ä½ç½®ç¼–ç  vs ä¸ä½¿ç”¨ä½ç½®ç¼–ç çš„æ¨¡å‹æ€§èƒ½"
            },
            "with_positional_encoding": {},
            "without_positional_encoding": {}
        }

    def train_model(self, use_positional_encoding=True, model_name="baseline"):
        """
        è®­ç»ƒå•ä¸ªæ¨¡å‹
        Args:
            use_positional_encoding: æ˜¯å¦ä½¿ç”¨ä½ç½®ç¼–ç 
            model_name: æ¨¡å‹åç§°æ ‡è¯†
        Returns:
            dict: è®­ç»ƒç»“æœå’Œæ¨¡å‹çŠ¶æ€
        """
        print(f"\n{'=' * 60}")
        print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
        print(f"ä½¿ç”¨ä½ç½®ç¼–ç : {use_positional_encoding}")
        print(f"{'=' * 60}")

        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
        set_seed(self.config.seed)

        # åˆ›å»ºæ¨¡å‹
        model = AblationTransformer(
            self.config,
            self.tokenizer,
            use_positional_encoding=use_positional_encoding
        ).to(self.device)

        # ä¼˜åŒ–å™¨
        optimizer = optim.AdamW(model.parameters(), lr=self.config.learning_rate)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=self.config.num_epochs
        )

        # æŸå¤±å‡½æ•°
        criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)

        # æ•°æ®åŠ è½½å™¨
        # train_loader, val_loader, test_loader, tokenizer = get_data_loaders(self.config)

        # è®­ç»ƒè®°å½•
        train_losses = []
        val_losses = []
        rouge_scores = []
        best_rouge = 0
        best_model_state = None

        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config.num_epochs):
            print(f"\nEpoch {epoch + 1}/{self.config.num_epochs}")

            # è®­ç»ƒé˜¶æ®µ
            model.train()
            total_train_loss = 0
            progress_bar = tqdm(self.train_loader, desc=f'è®­ç»ƒ {model_name}')

            for batch in progress_bar:
                # å‡†å¤‡æ•°æ®
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)

                # å‰å‘ä¼ æ’­
                outputs = model(input_ids, labels[:, :-1])
                logits = outputs['logits']

                # è®¡ç®—æŸå¤±
                loss = criterion(
                    logits.reshape(-1, logits.size(-1)),
                    labels[:, 1:].reshape(-1)
                )

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), self.config.max_grad_norm)
                optimizer.step()

                total_train_loss += loss.item()
                progress_bar.set_postfix({'loss': loss.item()})

            avg_train_loss = total_train_loss / len(self.train_loader)
            train_losses.append(avg_train_loss)

            # éªŒè¯é˜¶æ®µ
            avg_val_loss, rouge = self.validate_model(model, self.val_loader, criterion)
            val_losses.append(avg_val_loss)
            rouge_scores.append(rouge)

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']

            # æ‰“å°ç»“æœ
            print(f"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}, éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
            print(f"å­¦ä¹ ç‡: {current_lr:.2e}")
            print(f"ROUGE-1: {rouge['rouge1']:.4f}, ROUGE-2: {rouge['rouge2']:.4f}, ROUGE-L: {rouge['rougeL']:.4f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if rouge['rouge1'] > best_rouge:
                best_rouge = rouge['rouge1']
                best_model_state = {
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch,
                    'rouge': rouge
                }

        return {
            'model': model,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'rouge_scores': rouge_scores,
            'best_rouge': best_rouge,
            'best_model_state': best_model_state
        }

    def validate_model(self, model, val_loader, criterion):
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        model.eval()
        total_loss = 0
        all_predictions = []
        all_references = []

        with torch.no_grad():
            for batch in tqdm(val_loader, desc='éªŒè¯'):
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)

                # è®¡ç®—æŸå¤±
                outputs = model(input_ids, labels[:, :-1])
                logits = outputs['logits']
                loss = criterion(
                    logits.reshape(-1, logits.size(-1)),
                    labels[:, 1:].reshape(-1)
                )
                total_loss += loss.item()

                # ç”Ÿæˆé¢„æµ‹
                try:
                    predictions = model.generate(input_ids, max_length=self.config.max_target_length)
                    decoded_preds = self.tokenizer.batch_decode(predictions.cpu(), skip_special_tokens=True)
                    decoded_labels = self.tokenizer.batch_decode(labels.cpu(), skip_special_tokens=True)

                    all_predictions.extend(decoded_preds)
                    all_references.extend(decoded_labels)
                except Exception as e:
                    print(f"ç”Ÿæˆé¢„æµ‹æ—¶å‡ºé”™: {e}")
                    continue

        # è®¡ç®—ROUGEåˆ†æ•°
        if len(all_predictions) > 0:
            rouge = self.calculate_rouge(all_predictions, all_references)
        else:
            rouge = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}

        avg_loss = total_loss / len(val_loader)
        return avg_loss, rouge
    def calculate_rouge(self, predictions, references):
        """
        è®¡ç®—ROUGEè¯„ä¼°åˆ†æ•° - ç”¨äºè¯„ä¼°ç”Ÿæˆæ‘˜è¦çš„è´¨é‡
        ROUGE (Recall-Oriented Understudy for Gisting Evaluation) æ˜¯
        è‡ªåŠ¨æ–‡æ‘˜å’Œæœºå™¨ç¿»è¯‘é¢†åŸŸæœ€å¸¸ç”¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œé€šè¿‡æ¯”è¾ƒç”Ÿæˆæ–‡æœ¬ä¸
        å‚è€ƒæ–‡æœ¬çš„n-gramé‡å åº¦æ¥è¯„ä¼°è´¨é‡ã€‚
        Args:
            predictions (list[str]): æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬åˆ—è¡¨
                - æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»£è¡¨æ¨¡å‹å¯¹å•ä¸ªæ ·æœ¬çš„æ‘˜è¦ç”Ÿæˆç»“æœ
                - ç¤ºä¾‹: ["çŒ«åœ¨å«å­ä¸Šç¡è§‰", "ç‹—åœ¨é™¢å­é‡Œç©è€"]
            references (list[str]): äººå·¥æ’°å†™çš„å‚è€ƒæ‘˜è¦æ–‡æœ¬åˆ—è¡¨
                - æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»£è¡¨è¯¥æ ·æœ¬çš„æ ‡å‡†ç­”æ¡ˆï¼ˆé»„é‡‘æ‘˜è¦ï¼‰
                - ç¤ºä¾‹: ["ä¸€åªçŒ«åœ¨å«å­ä¸Šä¼‘æ¯", "ç‹—åœ¨èŠ±å›­é‡Œç©"]
                - æ³¨æ„ï¼šå¿…é¡»ä¸predictionsåˆ—è¡¨é¡ºåºä¸€è‡´ä¸”é•¿åº¦ç›¸åŒ
        Returns:
            dict: åŒ…å«ä¸‰ç§ROUGEåˆ†æ•°çš„å­—å…¸
                - 'rouge1': ROUGE-1åˆ†æ•°ï¼ˆåŸºäºå•ä¸ªå•è¯ï¼‰
                - 'rouge2': ROUGE-2åˆ†æ•°ï¼ˆåŸºäºå•è¯å¯¹ï¼‰
                - 'rougeL': ROUGE-Låˆ†æ•°ï¼ˆåŸºäºæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰
                - æ¯ä¸ªåˆ†æ•°éƒ½æ˜¯è¯¥æ‰¹æ¬¡æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ï¼ŒèŒƒå›´[0.0, 1.0]
        Note:
            ROUGEåˆ†æ•°è¶Šé«˜è¡¨ç¤ºç”Ÿæˆæ‘˜è¦ä¸å‚è€ƒæ‘˜è¦è¶Šç›¸ä¼¼ï¼Œè´¨é‡è¶Šå¥½
            é€šå¸¸ROUGE-1 > ROUGE-L > ROUGE-2ï¼Œå› ä¸ºåŒ¹é…è¦æ±‚é€æ¸ä¸¥æ ¼
        """
        # åˆå§‹åŒ–ROUGEè¯„åˆ†å™¨
        # RougeScoreræ˜¯rouge_scoreåº“çš„æ ¸å¿ƒç±»ï¼Œè´Ÿè´£è®¡ç®—å„ç§ROUGEæŒ‡æ ‡
        # å‚æ•°è¯´æ˜ï¼š
        # - ['rouge1', 'rouge2', 'rougeL']: åŒæ—¶è®¡ç®—ä¸‰ç§ROUGEåˆ†æ•°
        # - use_stemmer=True: å¯¹å•è¯è¿›è¡Œè¯å¹²æå–ï¼ˆå¦‚"running"â†’"run"ï¼‰
        #   å‡å°‘è¯å½¢å˜åŒ–å¯¹åŒ¹é…çš„å½±å“ï¼Œæé«˜è¯„ä¼°çš„è¯­ä¹‰å‡†ç¡®æ€§
        scorer = rouge_scorer.RougeScorer(
            ['rouge1', 'rouge2', 'rougeL'],  # æŒ‡å®šè¦è®¡ç®—çš„ROUGEç±»å‹
            use_stemmer=True  # å¯ç”¨è¯å¹²æå–ï¼Œæé«˜åŒ¹é…å‡†ç¡®æ€§
        )
        # åˆå§‹åŒ–åˆ†æ•°å­˜å‚¨åˆ—è¡¨
        rouge1_scores = []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ROUGE-1åˆ†æ•°
        rouge2_scores = []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ROUGE-2åˆ†æ•°
        rougeL_scores = []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ROUGE-Låˆ†æ•°

        # éå†æ¯ä¸ªæ ·æœ¬å¯¹ï¼ˆç”Ÿæˆæ‘˜è¦ vs å‚è€ƒæ‘˜è¦ï¼‰
        for pred, ref in zip(predictions, references):
            # è®¡ç®—å½“å‰æ ·æœ¬çš„ROUGEåˆ†æ•°
            # scorer.score() è¿”å›åŒ…å«precision, recall, fmeasureçš„å­—å…¸
            scores = scorer.score(ref, pred)
            # # scorer.score()è¿”å›çš„ä¸‰ç§æŒ‡æ ‡ï¼š
            # scores = {
            #     'rouge1': {
            #         'precision': 0.75,   # ç²¾ç¡®ç‡ï¼šç”Ÿæˆæ‘˜è¦ä¸­æœ‰å¤šå°‘æ˜¯æ­£ç¡®çš„
            #         'recall': 0.60,      # å¬å›ç‡ï¼šå‚è€ƒæ‘˜è¦ä¸­æœ‰å¤šå°‘è¢«è¦†ç›–
            #         'fmeasure': 0.67     # F1åˆ†æ•°ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
            #     }
            # }
            # æå–å¹¶å­˜å‚¨F1åˆ†æ•°ï¼ˆç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼‰
            # F1åˆ†æ•°ç»¼åˆè€ƒè™‘äº†ç”Ÿæˆæ‘˜è¦çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
            rouge1_scores.append(scores['rouge1'].fmeasure)  # å•è¯çº§åˆ«ç›¸ä¼¼åº¦
            rouge2_scores.append(scores['rouge2'].fmeasure)  # çŸ­è¯­çº§åˆ«ç›¸ä¼¼åº¦
            rougeL_scores.append(scores['rougeL'].fmeasure)  # å¥å­ç»“æ„ç›¸ä¼¼åº¦

        # è®¡ç®—æ‰¹æ¬¡å¹³å‡åˆ†æ•°å¹¶è¿”å›
        return {
            'rouge1': np.mean(rouge1_scores),  # å¹³å‡ROUGE-1åˆ†æ•°
            'rouge2': np.mean(rouge2_scores),  # å¹³å‡ROUGE-2åˆ†æ•°
            'rougeL': np.mean(rougeL_scores)  # å¹³å‡ROUGE-Låˆ†æ•°
        }
    def run_study(self):
        """è¿è¡Œå®Œæ•´çš„æ¶ˆèå®éªŒ"""
        print("å¼€å§‹ä½ç½®ç¼–ç æ¶ˆèå®éªŒ")
        print("=" * 60)

        # å®éªŒ1: ä½¿ç”¨ä½ç½®ç¼–ç ï¼ˆåŸºçº¿æ¨¡å‹ï¼‰
        print("\nğŸ”¬ å®éªŒ1: è®­ç»ƒå¸¦æœ‰ä½ç½®ç¼–ç çš„æ¨¡å‹ï¼ˆåŸºçº¿ï¼‰")
        baseline_results = self.train_model(
            use_positional_encoding=True,
            model_name="with_positional_encoding"
        )
        self.results["with_positional_encoding"] = {
            "final_train_loss": baseline_results['train_losses'][-1],
            "final_val_loss": baseline_results['val_losses'][-1],
            "final_rouge": baseline_results['rouge_scores'][-1],
            "best_rouge": baseline_results['best_rouge'],
            "all_rouge_scores": baseline_results['rouge_scores'],
            "train_losses": baseline_results['train_losses'],
            "val_losses": baseline_results['val_losses']
        }

        # å®éªŒ2: ä¸ä½¿ç”¨ä½ç½®ç¼–ç ï¼ˆæ¶ˆèæ¨¡å‹ï¼‰
        print("\nğŸ”¬ å®éªŒ2: è®­ç»ƒä¸å¸¦æœ‰ä½ç½®ç¼–ç çš„æ¨¡å‹ï¼ˆæ¶ˆèï¼‰")
        ablation_results = self.train_model(
            use_positional_encoding=False,
            model_name="without_positional_encoding"
        )
        self.results["without_positional_encoding"] = {
            "final_train_loss": ablation_results['train_losses'][-1],
            "final_val_loss": ablation_results['val_losses'][-1],
            "final_rouge": ablation_results['rouge_scores'][-1],
            "best_rouge": ablation_results['best_rouge'],
            "all_rouge_scores": ablation_results['rouge_scores'],
            "train_losses": ablation_results['train_losses'],
            "val_losses": ablation_results['val_losses']
        }

        # ä¿å­˜ç»“æœ
        self.save_results()

        # å¯è§†åŒ–æ¯”è¾ƒ
        self.visualize_comparison()

        # åˆ†æç»“æœ
        self.analyze_results()

        return self.results

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ä¿å­˜JSONç»“æœ
        results_file = os.path.join(self.results_dir, f"ablation_results_{self.config.num_epochs}epochs_{self.config.n_heads}heads.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        # ä¿å­˜æ–‡æœ¬æ‘˜è¦
        summary_file = os.path.join(self.results_dir, f"experiment_summary_{self.config.num_epochs}epochs_{self.config.n_heads}heads.txt")
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("ä½ç½®ç¼–ç æ¶ˆèå®éªŒæ‘˜è¦\n")
            f.write("=" * 50 + "\n\n")

            baseline = self.results["with_positional_encoding"]
            ablation = self.results["without_positional_encoding"]

            f.write("åŸºçº¿æ¨¡å‹ï¼ˆæœ‰ä½ç½®ç¼–ç ï¼‰:\n")
            f.write(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {baseline['final_train_loss']:.4f}\n")
            f.write(f"  æœ€ç»ˆéªŒè¯æŸå¤±: {baseline['final_val_loss']:.4f}\n")
            f.write(f"  æœ€ç»ˆROUGE-1: {baseline['final_rouge']['rouge1']:.4f}\n")
            f.write(f"  æœ€ä½³ROUGE-1: {baseline['best_rouge']:.4f}\n\n")

            f.write("æ¶ˆèæ¨¡å‹ï¼ˆæ— ä½ç½®ç¼–ç ï¼‰:\n")
            f.write(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {ablation['final_train_loss']:.4f}\n")
            f.write(f"  æœ€ç»ˆéªŒè¯æŸå¤±: {ablation['final_val_loss']:.4f}\n")
            f.write(f"  æœ€ç»ˆROUGE-1: {ablation['final_rouge']['rouge1']:.4f}\n")
            f.write(f"  æœ€ä½³ROUGE-1: {ablation['best_rouge']:.4f}\n\n")

            # è®¡ç®—å·®å¼‚
            rouge1_diff = baseline['final_rouge']['rouge1'] - ablation['final_rouge']['rouge1']
            rouge2_diff = baseline['final_rouge']['rouge2'] - ablation['final_rouge']['rouge2']
            rougeL_diff = baseline['final_rouge']['rougeL'] - ablation['final_rouge']['rougeL']

            f.write("æ€§èƒ½å·®å¼‚ï¼ˆåŸºçº¿ - æ¶ˆèï¼‰:\n")
            f.write(f"  ROUGE-1å·®å¼‚: {rouge1_diff:+.4f}\n")
            f.write(f"  ROUGE-2å·®å¼‚: {rouge2_diff:+.4f}\n")
            f.write(f"  ROUGE-Lå·®å¼‚: {rougeL_diff:+.4f}\n")

        print(f"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        print(f"âœ… å®éªŒæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")

    def visualize_comparison(self):
        """å¯è§†åŒ–æ¯”è¾ƒç»“æœ"""
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))

        baseline = self.results["with_positional_encoding"]
        ablation = self.results["without_positional_encoding"]

        epochs = range(1, len(baseline['train_losses']) + 1)

        # 1. è®­ç»ƒæŸå¤±æ¯”è¾ƒ
        axes[0, 0].plot(epochs, baseline['train_losses'], 'b-', label='æœ‰ä½ç½®ç¼–ç ', linewidth=2)
        axes[0, 0].plot(epochs, ablation['train_losses'], 'r-', label='æ— ä½ç½®ç¼–ç ', linewidth=2)
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('è®­ç»ƒæŸå¤±')
        axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ¯”è¾ƒ')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # 2. éªŒè¯æŸå¤±æ¯”è¾ƒ
        axes[0, 1].plot(epochs, baseline['val_losses'], 'b-', label='æœ‰ä½ç½®ç¼–ç ', linewidth=2)
        axes[0, 1].plot(epochs, ablation['val_losses'], 'r-', label='æ— ä½ç½®ç¼–ç ', linewidth=2)
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('éªŒè¯æŸå¤±')
        axes[0, 1].set_title('éªŒè¯æŸå¤±æ¯”è¾ƒ')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ROUGE-1åˆ†æ•°æ¯”è¾ƒ
        baseline_rouge1 = [score['rouge1'] for score in baseline['all_rouge_scores']]
        ablation_rouge1 = [score['rouge1'] for score in ablation['all_rouge_scores']]
        axes[1, 0].plot(epochs, baseline_rouge1, 'b-', label='æœ‰ä½ç½®ç¼–ç ', linewidth=2)
        axes[1, 0].plot(epochs, ablation_rouge1, 'r-', label='æ— ä½ç½®ç¼–ç ', linewidth=2)
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('ROUGE-1åˆ†æ•°')
        axes[1, 0].set_title('ROUGE-1åˆ†æ•°æ¯”è¾ƒ')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # 4. æœ€ç»ˆæ€§èƒ½æŸ±çŠ¶å›¾
        metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']
        baseline_scores = [
            baseline['final_rouge']['rouge1'],
            baseline['final_rouge']['rouge2'],
            baseline['final_rouge']['rougeL']
        ]
        ablation_scores = [
            ablation['final_rouge']['rouge1'],
            ablation['final_rouge']['rouge2'],
            ablation['final_rouge']['rougeL']
        ]

        x = np.arange(len(metrics))
        width = 0.35
        axes[1, 1].bar(x - width / 2, baseline_scores, width, label='æœ‰ä½ç½®ç¼–ç ', alpha=0.8)
        axes[1, 1].bar(x + width / 2, ablation_scores, width, label='æ— ä½ç½®ç¼–ç ', alpha=0.8)
        axes[1, 1].set_xlabel('è¯„ä¼°æŒ‡æ ‡')
        axes[1, 1].set_ylabel('åˆ†æ•°')
        axes[1, 1].set_title('æœ€ç»ˆæ€§èƒ½æ¯”è¾ƒ')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(metrics)
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plot_file = os.path.join(self.results_dir, f"ablation_comparison_{self.config.num_epochs}epochs_{self.config.n_heads}heads.png")
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"âœ… æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜åˆ°: {plot_file}")

    def analyze_results(self):
        """åˆ†æå®éªŒç»“æœå¹¶ç”Ÿæˆè§è§£"""
        baseline = self.results["with_positional_encoding"]
        ablation = self.results["without_positional_encoding"]

        print("\n" + "=" * 60)
        print("ğŸ” ä½ç½®ç¼–ç æ¶ˆèå®éªŒåˆ†æç»“æœ")
        print("=" * 60)

        # è®¡ç®—æ€§èƒ½å·®å¼‚
        rouge1_diff = baseline['final_rouge']['rouge1'] - ablation['final_rouge']['rouge1']
        rouge2_diff = baseline['final_rouge']['rouge2'] - ablation['final_rouge']['rouge2']
        rougeL_diff = baseline['final_rouge']['rougeL'] - ablation['final_rouge']['rougeL']

        # è®­ç»ƒç¨³å®šæ€§åˆ†æ
        baseline_loss_std = np.std(baseline['train_losses'][-5:])  # æœ€å5ä¸ªepochçš„æ ‡å‡†å·®
        ablation_loss_std = np.std(ablation['train_losses'][-5:])

        print(f"\nğŸ“Š æ€§èƒ½æ¯”è¾ƒ:")
        print(f"ROUGE-1å·®å¼‚: {rouge1_diff:+.4f} ({rouge1_diff / baseline['final_rouge']['rouge1']:+.1%})")
        print(f"ROUGE-2å·®å¼‚: {rouge2_diff:+.4f} ({rouge2_diff / baseline['final_rouge']['rouge2']:+.1%})")
        print(f"ROUGE-Lå·®å¼‚: {rougeL_diff:+.4f} ({rougeL_diff / baseline['final_rouge']['rougeL']:+.1%})")

        print(f"\nğŸ“ˆ è®­ç»ƒç¨³å®šæ€§:")
        print(f"åŸºçº¿æ¨¡å‹æŸå¤±æ ‡å‡†å·®: {baseline_loss_std:.4f}")
        print(f"æ¶ˆèæ¨¡å‹æŸå¤±æ ‡å‡†å·®: {ablation_loss_std:.4f}")

        # ç”Ÿæˆè§è§£
        print(f"\nğŸ’¡ å®éªŒå‘ç°ä¸è§è§£:")

        if rouge1_diff > 0.1:
            print("1. ğŸ¯ ä½ç½®ç¼–ç å¯¹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“")
            print("   - ä½ç½®ç¼–ç æä¾›äº†å…³é”®çš„åºåˆ—é¡ºåºä¿¡æ¯")
            print("   - å¯¹äºæ‘˜è¦ç”Ÿæˆä»»åŠ¡ï¼Œç†è§£å¯¹è¯é¡ºåºè‡³å…³é‡è¦")
        elif rouge1_diff > 0.05:
            print("1. âš ï¸ ä½ç½®ç¼–ç å¯¹æ¨¡å‹æ€§èƒ½æœ‰ä¸­ç­‰å½±å“")
            print("   - ä½ç½®ä¿¡æ¯æœ‰åŠ©äºä½†ä¸å®Œå…¨å†³å®šæ¨¡å‹æ€§èƒ½")
            print("   - æ¨¡å‹å¯èƒ½ä»å†…å®¹ä¸­å­¦ä¹ åˆ°éƒ¨åˆ†é¡ºåºä¿¡æ¯")
        else:
            print("1. ğŸ”„ ä½ç½®ç¼–ç å¯¹æ¨¡å‹æ€§èƒ½å½±å“è¾ƒå°")
            print("   - æ¨¡å‹å¯èƒ½ä¸»è¦ä¾èµ–å†…å®¹ä¿¡æ¯è€Œéé¡ºåºä¿¡æ¯")
            print("   - æˆ–è€…æ¨¡å‹é€šè¿‡å…¶ä»–æ–¹å¼å­¦ä¹ åˆ°äº†é¡ºåºå…³ç³»")

        if ablation_loss_std > baseline_loss_std * 1.5:
            print("2. ğŸ“‰ æ— ä½ç½®ç¼–ç æ—¶è®­ç»ƒæ›´ä¸ç¨³å®š")
            print("   - ä½ç½®ç¼–ç æœ‰åŠ©äºè®­ç»ƒæ”¶æ•›å’Œç¨³å®šæ€§")
            print("   - ç¼ºä¹ä½ç½®ä¿¡æ¯å¯èƒ½å¯¼è‡´ä¼˜åŒ–å›°éš¾")
        else:
            print("2. ğŸ“Š è®­ç»ƒç¨³å®šæ€§ç›¸å½“")
            print("   - ä½ç½®ç¼–ç å¯¹è®­ç»ƒç¨³å®šæ€§å½±å“æœ‰é™")

        print("3. ğŸ”¬ æŠ€æœ¯è§è§£:")
        print("   - Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æœ¬èº«ä¸å…·å¤‡ä½ç½®æ„ŸçŸ¥èƒ½åŠ›")
        print("   - ä½ç½®ç¼–ç æ˜¯åºåˆ—é¡ºåºä¿¡æ¯çš„å”¯ä¸€æ¥æº")
        print("   - åœ¨å¯¹è¯æ‘˜è¦ä»»åŠ¡ä¸­ï¼Œæ—¶é—´é¡ºåºå¯¹ç†è§£å¯¹è¯æµç¨‹å¾ˆé‡è¦")

        print("4. ğŸš€ å®è·µå»ºè®®:")
        if rouge1_diff > 0.05:
            print("   - åœ¨ç±»ä¼¼ä»»åŠ¡ä¸­å¿…é¡»ä½¿ç”¨ä½ç½®ç¼–ç ")
            print("   - å¯ä»¥å°è¯•æ›´å¤æ‚çš„ä½ç½®ç¼–ç æ–¹æ¡ˆï¼ˆå¦‚ç›¸å¯¹ä½ç½®ç¼–ç ï¼‰")
        else:
            print("   - å¯¹äºæŸäº›ä»»åŠ¡ï¼Œå¯ä»¥ç®€åŒ–æ¨¡å‹æ¶æ„")
            print("   - ä½†ä»å»ºè®®ä½¿ç”¨ä½ç½®ç¼–ç ä»¥ç¡®ä¿æœ€ä½³æ€§èƒ½")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ¶ˆèå®éªŒ"""
    # è®¾ç½®éšæœºç§å­
    set_seed(config.seed)
    print("è®¾ç½®éšæœºç§å­å®Œæˆ")

    # ä¸ºæ¶ˆèå®éªŒè°ƒæ•´é…ç½®ï¼ˆåŠ å¿«å®éªŒé€Ÿåº¦ï¼‰
    config.num_epochs = 2  # å‡å°‘è®­ç»ƒè½®æ•°è¿›è¡Œå¿«é€Ÿå®éªŒ
    config.batch_size = 16  # å‡å°æ‰¹æ¬¡å¤§å°

    # è·å–æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_loader, val_loader, test_loader, tokenizer = get_data_loaders(config)

    # è¿è¡Œæ¶ˆèå®éªŒ
    study = AblationStudy(config, tokenizer,train_loader, val_loader, test_loader)
    results = study.run_study()

    print("\nğŸ‰ æ¶ˆèå®éªŒå®Œæˆï¼")
    print(f"ç»“æœä¿å­˜åœ¨: {study.results_dir}")


if __name__ == "__main__":
    main()